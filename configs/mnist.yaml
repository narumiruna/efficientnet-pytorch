trainer:
  name: "Trainer"
  num_epochs: 90
  output_dir: experiments/mnist

model:
  name: efficientnet_b0
  num_classes: 10

dataset:
  name: MNISTDataLoader
  root: data
  batch_size: 32
  image_size: 32
  num_workers: 0

optimizer:
  name: SGD
  lr: 1.25e-2
  weight_decay: 1.e-4
  momentum: 0.9
  nesterov: true

scheduler:
  name: MultiStepLR
  milestones: [30, 60, 80]
  gamma: 0.1
